import feedparser
import os
from datetime import datetime
import re
import json

def sanitize_filename(filename):
    return re.sub(r'[<>:"/\\|?*]', '', filename)

def parse_date(date_string):
    try:
        return datetime.strptime(date_string, '%a, %d %b %Y %H:%M:%S %z')
    except ValueError:
        try:
            return datetime.strptime(date_string.split('+')[0].strip(), '%a, %d %b %Y %H:%M:%S')
        except ValueError:
            print(f"Warning: Could not parse date '{date_string}', using current time")
            return datetime.now()

def normalize_content(content):
    """Normalize content by standardizing line endings and removing trailing whitespace"""
    return '\n'.join(line.rstrip() for line in content.splitlines()).strip()

# Track changes
new_files = []
updated_files = []

feed_url = 'https://store.steampowered.com/feeds/news/app/2106670/?cc=US&l=english&snr=1_2108_9__2107'
feed = feedparser.parse(feed_url)

os.makedirs('content/PatchNotes', exist_ok=True)

for entry in feed.entries:
    title = entry.title
    description = entry.description
    date_str = parse_date(entry.published)
    
    safe_title = sanitize_filename(title)
    file_name = f"content/PatchNotes/{safe_title}.md"
    
    # Check if file already exists
    is_new_file = not os.path.exists(file_name)
    
    # Build the frontmatter
    frontmatter = "---\n"
    frontmatter += f"link: '{entry.link}'\n"
    frontmatter += "author: 'Steam'\n"
    frontmatter += f"date: '{date_str.strftime('%Y-%m-%dT%H:%M:%S')}'\n"
    frontmatter += "tags: ['patch-notes']\n"
    frontmatter += "---\n\n"
    
    content = f"# {title}\n\n{description}\n\nPublished on: {entry.published}"
    file_content = normalize_content(frontmatter + content)

    # If file exists, check if content is different
    if not is_new_file:
        try:
            with open(file_name, 'r', encoding='utf-8') as f:
                existing_content = normalize_content(f.read())
            if existing_content == file_content:
                print(f"Skipping {file_name} - content unchanged")
                continue  # Skip if content hasn't changed
            print(f"Content different for {file_name}")
            print("Existing content hash:", hash(existing_content))
            print("New content hash:", hash(file_content))
            updated_files.append(file_name)
        except Exception as e:
            print(f"Error reading existing file: {e}")
            updated_files.append(file_name)
    else:
        new_files.append(file_name)

    # Write the file
    with open(file_name, 'w', encoding='utf-8', newline='\n') as f:
        f.write(file_content)
    
    print(f"{'Created' if is_new_file else 'Updated'} file: {file_name}")

# Set outputs for use in PR creation
with open(os.environ['GITHUB_ENV'], 'a') as f:
    f.write(f'NEW_FILES_COUNT={len(new_files)}\n')
    f.write(f'UPDATED_FILES_COUNT={len(updated_files)}\n')
    f.write(f'NEW_FILES={",".join(new_files)}\n')
    f.write(f'UPDATED_FILES={",".join(updated_files)}\n')

# Write change summary
summary = {
    'has_changes': bool(new_files or updated_files),
    'new_files': len(new_files),
    'updated_files': len(updated_files),
    'files': {
        'new': new_files,
        'updated': updated_files
    }
}

with open('change_summary.json', 'w') as f:
    json.dump(summary, f)

# Set the has_changes output
with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
    f.write(f'has_changes={str(bool(new_files or updated_files)).lower()}\n')
